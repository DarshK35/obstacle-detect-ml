{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing out code segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshk/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/darshk/miniconda3/envs/tf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expConfig = exp_factory.get_exp_config('retinanet_resnetfpn_coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 4\n",
    "\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "IMG_SIZE = [HEIGHT, WIDTH, 3]\n",
    "\n",
    "# Backbone config.\n",
    "expConfig.task.freeze_backbone = False\n",
    "expConfig.task.annotation_file = ''\n",
    "\n",
    "# Model config.\n",
    "expConfig.task.model.input_size = IMG_SIZE\n",
    "expConfig.task.model.num_classes = num_classes\n",
    "expConfig.task.model.detection_generator.tflite_post_processing.max_classes_per_detection = expConfig.task.model.num_classes\n",
    "\n",
    "# Training data config.\n",
    "expConfig.task.train_data.input_path = \"../Dataset/road_coco/records/train-00000-of-00001.tfrecord\"\n",
    "expConfig.task.train_data.dtype = 'float32'\n",
    "expConfig.task.train_data.global_batch_size = batch_size\n",
    "expConfig.task.train_data.parser.aug_scale_max = 1.0\n",
    "expConfig.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation data config.\n",
    "expConfig.task.validation_data.input_path = \"../Dataset/road_coco/records/valid-00000-of-00001.tfrecord\"\n",
    "expConfig.task.validation_data.dtype = 'float32'\n",
    "expConfig.task.validation_data.global_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 2500\n",
    "expConfig.trainer.steps_per_loop = 88 # steps_per_loop = num_of_training_examples // train_batch_size\n",
    "\n",
    "expConfig.trainer.summary_interval = 88\n",
    "expConfig.trainer.checkpoint_interval = 250\n",
    "expConfig.trainer.validation_interval = 110\n",
    "expConfig.trainer.validation_steps =  22 # validation_steps = num_of_validation_examples // eval_batch_size\n",
    "expConfig.trainer.train_steps = train_steps\n",
    "expConfig.trainer.optimizer_config.warmup.linear.warmup_steps = 100\n",
    "expConfig.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "expConfig.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "expConfig.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.4\n",
    "expConfig.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'runtime': {   'all_reduce_alg': None,\n",
      "                   'batchnorm_spatial_persistent': False,\n",
      "                   'dataset_num_private_threads': None,\n",
      "                   'default_shard_dim': -1,\n",
      "                   'distribution_strategy': 'mirrored',\n",
      "                   'enable_xla': False,\n",
      "                   'gpu_thread_mode': None,\n",
      "                   'loss_scale': None,\n",
      "                   'mixed_precision_dtype': 'bfloat16',\n",
      "                   'num_cores_per_replica': 1,\n",
      "                   'num_gpus': 0,\n",
      "                   'num_packs': 1,\n",
      "                   'per_gpu_thread_count': 0,\n",
      "                   'run_eagerly': False,\n",
      "                   'task_index': -1,\n",
      "                   'tpu': None,\n",
      "                   'tpu_enable_xla_dynamic_padder': None,\n",
      "                   'worker_hosts': None},\n",
      "    'task': {   'allow_image_summary': False,\n",
      "                'annotation_file': '',\n",
      "                'differential_privacy_config': None,\n",
      "                'export_config': {   'cast_detection_classes_to_float': False,\n",
      "                                     'cast_num_detections_to_float': False,\n",
      "                                     'output_intermediate_features': False,\n",
      "                                     'output_normalized_coordinates': False},\n",
      "                'freeze_backbone': False,\n",
      "                'init_checkpoint': 'gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet/ckpt-28080',\n",
      "                'init_checkpoint_modules': 'backbone',\n",
      "                'losses': {   'box_loss_weight': 50,\n",
      "                              'focal_loss_alpha': 0.25,\n",
      "                              'focal_loss_gamma': 1.5,\n",
      "                              'huber_loss_delta': 0.1,\n",
      "                              'l2_weight_decay': 0.0001,\n",
      "                              'loss_weight': 1.0},\n",
      "                'max_num_eval_detections': 100,\n",
      "                'model': {   'anchor': {   'anchor_size': 4.0,\n",
      "                                           'aspect_ratios': [0.5, 1.0, 2.0],\n",
      "                                           'num_scales': 3},\n",
      "                             'backbone': {   'resnet': {   'bn_trainable': True,\n",
      "                                                           'depth_multiplier': 1.0,\n",
      "                                                           'model_id': 50,\n",
      "                                                           'replace_stem_max_pool': False,\n",
      "                                                           'resnetd_shortcut': False,\n",
      "                                                           'scale_stem': True,\n",
      "                                                           'se_ratio': 0.0,\n",
      "                                                           'stem_type': 'v0',\n",
      "                                                           'stochastic_depth_drop_rate': 0.0},\n",
      "                                             'type': 'resnet'},\n",
      "                             'decoder': {   'fpn': {   'fusion_type': 'sum',\n",
      "                                                       'num_filters': 256,\n",
      "                                                       'use_keras_layer': False,\n",
      "                                                       'use_separable_conv': False},\n",
      "                                            'type': 'fpn'},\n",
      "                             'detection_generator': {   'apply_nms': True,\n",
      "                                                        'max_num_detections': 100,\n",
      "                                                        'nms_iou_threshold': 0.5,\n",
      "                                                        'nms_version': 'v2',\n",
      "                                                        'pre_nms_score_threshold': 0.05,\n",
      "                                                        'pre_nms_top_k': 5000,\n",
      "                                                        'return_decoded': None,\n",
      "                                                        'soft_nms_sigma': None,\n",
      "                                                        'tflite_post_processing': {   'max_classes_per_detection': 4,\n",
      "                                                                                      'max_detections': 200,\n",
      "                                                                                      'nms_iou_threshold': 0.5,\n",
      "                                                                                      'nms_score_threshold': 0.1,\n",
      "                                                                                      'normalize_anchor_coordinates': False,\n",
      "                                                                                      'use_regular_nms': False},\n",
      "                                                        'use_class_agnostic_nms': False,\n",
      "                                                        'use_cpu_nms': False},\n",
      "                             'head': {   'attribute_heads': [],\n",
      "                                         'num_convs': 4,\n",
      "                                         'num_filters': 256,\n",
      "                                         'share_classification_heads': False,\n",
      "                                         'use_separable_conv': False},\n",
      "                             'input_size': [256, 256, 3],\n",
      "                             'max_level': 7,\n",
      "                             'min_level': 3,\n",
      "                             'norm_activation': {   'activation': 'relu',\n",
      "                                                    'norm_epsilon': 0.001,\n",
      "                                                    'norm_momentum': 0.99,\n",
      "                                                    'use_sync_bn': False},\n",
      "                             'num_classes': 4},\n",
      "                'name': None,\n",
      "                'per_category_metrics': False,\n",
      "                'train_data': {   'apply_tf_data_service_before_batching': False,\n",
      "                                  'block_length': 1,\n",
      "                                  'cache': False,\n",
      "                                  'cycle_length': None,\n",
      "                                  'decoder': {   'simple_decoder': {   'attribute_names': [   ],\n",
      "                                                                       'mask_binarize_threshold': None,\n",
      "                                                                       'regenerate_source_id': False},\n",
      "                                                 'type': 'simple_decoder'},\n",
      "                                  'deterministic': None,\n",
      "                                  'drop_remainder': True,\n",
      "                                  'dtype': 'float32',\n",
      "                                  'enable_shared_tf_data_service_between_parallel_trainers': False,\n",
      "                                  'enable_tf_data_service': False,\n",
      "                                  'file_type': 'tfrecord',\n",
      "                                  'global_batch_size': 8,\n",
      "                                  'input_path': '../Dataset/road_coco/records/train-00000-of-00001.tfrecord',\n",
      "                                  'is_training': True,\n",
      "                                  'parser': {   'aug_policy': None,\n",
      "                                                'aug_rand_hflip': True,\n",
      "                                                'aug_scale_max': 1.0,\n",
      "                                                'aug_scale_min': 1.0,\n",
      "                                                'aug_type': None,\n",
      "                                                'match_threshold': 0.5,\n",
      "                                                'max_num_instances': 100,\n",
      "                                                'num_channels': 3,\n",
      "                                                'skip_crowd_during_training': True,\n",
      "                                                'unmatched_threshold': 0.5},\n",
      "                                  'prefetch_buffer_size': None,\n",
      "                                  'seed': None,\n",
      "                                  'sharding': True,\n",
      "                                  'shuffle_buffer_size': 10000,\n",
      "                                  'tf_data_service_address': None,\n",
      "                                  'tf_data_service_job_name': None,\n",
      "                                  'tfds_as_supervised': False,\n",
      "                                  'tfds_data_dir': '',\n",
      "                                  'tfds_name': '',\n",
      "                                  'tfds_skip_decoding_feature': '',\n",
      "                                  'tfds_split': '',\n",
      "                                  'trainer_id': None,\n",
      "                                  'weights': None},\n",
      "                'use_coco_metrics': True,\n",
      "                'use_wod_metrics': False,\n",
      "                'validation_data': {   'apply_tf_data_service_before_batching': False,\n",
      "                                       'block_length': 1,\n",
      "                                       'cache': False,\n",
      "                                       'cycle_length': None,\n",
      "                                       'decoder': {   'simple_decoder': {   'attribute_names': [   ],\n",
      "                                                                            'mask_binarize_threshold': None,\n",
      "                                                                            'regenerate_source_id': False},\n",
      "                                                      'type': 'simple_decoder'},\n",
      "                                       'deterministic': None,\n",
      "                                       'drop_remainder': True,\n",
      "                                       'dtype': 'float32',\n",
      "                                       'enable_shared_tf_data_service_between_parallel_trainers': False,\n",
      "                                       'enable_tf_data_service': False,\n",
      "                                       'file_type': 'tfrecord',\n",
      "                                       'global_batch_size': 8,\n",
      "                                       'input_path': '../Dataset/road_coco/records/valid-00000-of-00001.tfrecord',\n",
      "                                       'is_training': False,\n",
      "                                       'parser': {   'aug_policy': None,\n",
      "                                                     'aug_rand_hflip': False,\n",
      "                                                     'aug_scale_max': 1.0,\n",
      "                                                     'aug_scale_min': 1.0,\n",
      "                                                     'aug_type': None,\n",
      "                                                     'match_threshold': 0.5,\n",
      "                                                     'max_num_instances': 100,\n",
      "                                                     'num_channels': 3,\n",
      "                                                     'skip_crowd_during_training': True,\n",
      "                                                     'unmatched_threshold': 0.5},\n",
      "                                       'prefetch_buffer_size': None,\n",
      "                                       'seed': None,\n",
      "                                       'sharding': True,\n",
      "                                       'shuffle_buffer_size': 10000,\n",
      "                                       'tf_data_service_address': None,\n",
      "                                       'tf_data_service_job_name': None,\n",
      "                                       'tfds_as_supervised': False,\n",
      "                                       'tfds_data_dir': '',\n",
      "                                       'tfds_name': '',\n",
      "                                       'tfds_skip_decoding_feature': '',\n",
      "                                       'tfds_split': '',\n",
      "                                       'trainer_id': None,\n",
      "                                       'weights': None}},\n",
      "    'trainer': {   'allow_tpu_summary': False,\n",
      "                   'best_checkpoint_eval_metric': '',\n",
      "                   'best_checkpoint_export_subdir': '',\n",
      "                   'best_checkpoint_metric_comp': 'higher',\n",
      "                   'checkpoint_interval': 250,\n",
      "                   'continuous_eval_timeout': 3600,\n",
      "                   'eval_tf_function': True,\n",
      "                   'eval_tf_while_loop': False,\n",
      "                   'loss_upper_bound': 1000000.0,\n",
      "                   'max_to_keep': 5,\n",
      "                   'optimizer_config': {   'ema': None,\n",
      "                                           'learning_rate': {   'cosine': {   'alpha': 0.0,\n",
      "                                                                              'decay_steps': 2500,\n",
      "                                                                              'initial_learning_rate': 0.4,\n",
      "                                                                              'name': 'CosineDecay',\n",
      "                                                                              'offset': 0},\n",
      "                                                                'type': 'cosine'},\n",
      "                                           'optimizer': {   'sgd': {   'clipnorm': None,\n",
      "                                                                       'clipvalue': None,\n",
      "                                                                       'decay': 0.0,\n",
      "                                                                       'global_clipnorm': None,\n",
      "                                                                       'momentum': 0.9,\n",
      "                                                                       'name': 'SGD',\n",
      "                                                                       'nesterov': False},\n",
      "                                                            'type': 'sgd'},\n",
      "                                           'warmup': {   'linear': {   'name': 'linear',\n",
      "                                                                       'warmup_learning_rate': 0.24,\n",
      "                                                                       'warmup_steps': 100},\n",
      "                                                         'type': 'linear'}},\n",
      "                   'preemption_on_demand_checkpoint': True,\n",
      "                   'recovery_begin_steps': 0,\n",
      "                   'recovery_max_trials': 0,\n",
      "                   'steps_per_loop': 88,\n",
      "                   'summary_interval': 88,\n",
      "                   'train_steps': 2500,\n",
      "                   'train_tf_function': True,\n",
      "                   'train_tf_while_loop': True,\n",
      "                   'validation_interval': 110,\n",
      "                   'validation_steps': 22,\n",
      "                   'validation_summary_subdir': 'validation'}}\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "pp.pprint(expConfig.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "if expConfig.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "distStrat = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distStrat.scope():\n",
    "    task = tfm.core.task_factory.get_task(expConfig.task, logging_dir=\"./train-model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in task.build_inputs(expConfig.task.train_data).take(1):\n",
    "  print()\n",
    "  print(f'images.shape: {str(images.shape):16}  images.dtype: {images.dtype!r}')\n",
    "  print(f'labels.keys: {labels.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryIndex = {\n",
    "\t0: {\n",
    "\t\t'id': 0,\n",
    "\t\t'name': \"speedlimit\"\n",
    "\t},\n",
    "\t1: {\n",
    "\t\t'id': 1,\n",
    "\t\t'name': \"crosswalk\"\n",
    "\t},\n",
    "\t2: {\n",
    "\t\t'id': 2,\n",
    "\t\t'name': \"trafficlight\"\n",
    "\t},\n",
    "\t3: {\n",
    "\t\t'id': 3,\n",
    "\t\t'name': \"stop\"\n",
    "\t}\n",
    "}\n",
    "\n",
    "tfExDecoder = TfExampleDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(raw_records, num_of_examples):\n",
    "  plt.figure(figsize=(5, 5))\n",
    "  use_normalized_coordinates=True\n",
    "  min_score_thresh = 0.30\n",
    "  for i, serialized_example in enumerate(raw_records):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    decoded_tensors = tfExDecoder.decode(serialized_example)\n",
    "    image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "    scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "        decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "        scores,\n",
    "        category_index=categoryIndex,\n",
    "        use_normalized_coordinates=use_normalized_coordinates,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        agnostic_mode=False,\n",
    "        instance_masks=None,\n",
    "        line_thickness=4)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image-{i+1}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20\n",
    "num_of_examples = 3\n",
    "\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "raw_records = tf.data.TFRecordDataset(\n",
    "    expConfig.task.train_data.input_path).shuffle(\n",
    "        buffer_size=buffer_size).take(num_of_examples)\n",
    "show_batch(raw_records, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "    distribution_strategy=distStrat,\n",
    "    task=task,\n",
    "    mode='train_and_eval',\n",
    "    params=expConfig,\n",
    "    model_dir=\"./train-model/\",\n",
    "    run_post_eval=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "\timage = None\n",
    "\tif(path.startswith('http')):\n",
    "\t\tresponse = urlopen(path)\n",
    "\t\timage_data = response.read()\n",
    "\t\timage_data = BytesIO(image_data)\n",
    "\t\timage = Image.open(image_data)\n",
    "\telse:\n",
    "\t\timage_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "\t\timage = Image.open(BytesIO(image_data))\n",
    "\n",
    "\t(im_width, im_height) = image.size\n",
    "\treturn np.array(image.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def build_inputs_for_object_detection(image, input_image_size):\n",
    "\timage, _ = resize_and_crop_image(\n",
    "\t\timage,\n",
    "\t\tinput_image_size,\n",
    "\t\tpadded_size=input_image_size,\n",
    "\t\taug_scale_min=1.0,\n",
    "\t\taug_scale_max=1.0)\n",
    "\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load('./export-model/')\n",
    "model_fn = imported.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testDs = tf.data.TFRecordDataset(\n",
    "    '../Dataset/road_coco/records/test-00000-of-00001.tfrecord').take(\n",
    "        num_of_examples)\n",
    "show_batch(testDs, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detection_classes': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>, 'image_info': <tf.Tensor: shape=(1, 4, 2), dtype=float32, numpy=\n",
      "array([[[256., 256.],\n",
      "        [256., 256.],\n",
      "        [  1.,   1.],\n",
      "        [  0.,   0.]]], dtype=float32)>, 'num_detections': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, 'detection_boxes': <tf.Tensor: shape=(1, 100, 4), dtype=float32, numpy=\n",
      "array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]], dtype=float32)>, 'detection_scores': <tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
      "array([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0.]], dtype=float32)>}\n",
      "{'detection_classes': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>, 'image_info': <tf.Tensor: shape=(1, 4, 2), dtype=float32, numpy=\n",
      "array([[[256., 256.],\n",
      "        [256., 256.],\n",
      "        [  1.,   1.],\n",
      "        [  0.,   0.]]], dtype=float32)>, 'num_detections': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, 'detection_boxes': <tf.Tensor: shape=(1, 100, 4), dtype=float32, numpy=\n",
      "array([[[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]], dtype=float32)>, 'detection_scores': <tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
      "array([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0., -0., -0., -0., -0., -0., -0., -0., -0.]], dtype=float32)>}\n",
      "{'detection_classes': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>, 'image_info': <tf.Tensor: shape=(1, 4, 2), dtype=float32, numpy=\n",
      "array([[[256., 256.],\n",
      "        [256., 256.],\n",
      "        [  1.,   1.],\n",
      "        [  0.,   0.]]], dtype=float32)>, 'num_detections': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, 'detection_boxes': <tf.Tensor: shape=(1, 100, 4), dtype=float32, numpy=\n",
      "array([[[ 28.226135,  47.1092  , 256.      , 256.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ],\n",
      "        [  0.      ,   0.      ,   0.      ,   0.      ]]], dtype=float32)>, 'detection_scores': <tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
      "array([[ 0.05175351, -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ]],\n",
      "      dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "input_image_size = (HEIGHT, WIDTH)\n",
    "plt.figure(figsize=(20, 20))\n",
    "min_score_thresh = 0.30 # Change minimum score for threshold to see all bounding boxes confidences.\n",
    "\n",
    "for i, serialized_example in enumerate(testDs):\n",
    "  plt.subplot(1, 3, i+1)\n",
    "  decoded = tfExDecoder.decode(serialized_example)\n",
    "  image = build_inputs_for_object_detection(decoded['image'], input_image_size)\n",
    "  image = tf.expand_dims(image, axis=0)\n",
    "  image = tf.cast(image, dtype = tf.uint8)\n",
    "  image_np = image[0].numpy()\n",
    "  result = model_fn(image)\n",
    "  print(result)\n",
    "  visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      result['detection_boxes'][0].numpy(),\n",
    "      result['detection_classes'][0].numpy().astype(int),\n",
    "      result['detection_scores'][0].numpy(),\n",
    "      category_index=categoryIndex,\n",
    "      use_normalized_coordinates=False,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=min_score_thresh,\n",
    "      agnostic_mode=False,\n",
    "      instance_masks=None,\n",
    "      line_thickness=4)\n",
    "  plt.imshow(image_np)\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6ecb354e549d542d2696753d3488a00b1fa25803065f5e1f812629d0abb59f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
